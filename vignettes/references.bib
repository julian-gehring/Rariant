
@article{agresti_dealing_2003,
	title = {Dealing with discreteness: makingexact{\textquoteright}confidence intervals for proportions, differences of proportions, and odds ratios more exact},
	volume = {12},
	shorttitle = {Dealing with discreteness},
	url = {http://smm.sagepub.com/content/12/1/3.short},
	number = {1},
	urldate = {2013-12-09},
	journal = {Statistical Methods in Medical Research},
	author = {Agresti, Alan},
	year = {2003},
	pages = {3{\textendash}21},
	file = {[PDF] von ufl.edu:/home/julian/embl/paper/storage/P7GV96WF/Agresti - 2003 - Dealing with discreteness makingexact{\textquoteright}confidence .pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/F3M9WSN7/3.html:text/html}
}

@article{agresti_score_2011,
	title = {Score and pseudo-score confidence intervals for categorical data analysis},
	volume = {3},
	url = {http://amstat.tandfonline.com/doi/full/10.1198/sbr.2010.09053},
	number = {2},
	urldate = {2013-12-10},
	journal = {Statistics in Biopharmaceutical Research},
	author = {Agresti, Alan},
	year = {2011},
	file = {[PDF] von ufl.edu:/home/julian/embl/paper/storage/C4VD7S92/Agresti - 2011 - Score and pseudo-score confidence intervals for ca.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/U3TMA446/cookieAbsent.html:text/html}
}

@book{agresti_categorical_2013,
	address = {Hoboken, {NJ}},
	title = {Categorical data analysis},
	isbn = {9780470463635  0470463635},
	language = {English},
	publisher = {Wiley},
	author = {Agresti, Alan},
	year = {2013}
}

@article{agresti_simple_2000,
	title = {Simple and effective confidence intervals for proportions and differences of proportions result from adding two successes and two failures},
	volume = {54},
	url = {http://amstat.tandfonline.com/doi/full/10.1080/00031305.2000.10474560},
	number = {4},
	urldate = {2014-01-16},
	journal = {The American Statistician},
	author = {Agresti, Alan and Caffo, Brian},
	year = {2000},
	pages = {280{\textendash}288},
	file = {Snapshot:/home/julian/embl/paper/storage/WFNSHDJD/cookieAbsent.html:text/html}
}

@article{agresti_approximate_1998,
	title = {Approximate is better than {\textquotedblleft}exact{\textquotedblright} for interval estimation of binomial proportions},
	volume = {52},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1998.10480550},
	number = {2},
	urldate = {2013-12-09},
	journal = {The American Statistician},
	author = {Agresti, Alan and Coull, Brent A.},
	year = {1998},
	pages = {119{\textendash}126},
	file = {[PDF] von csueastbay.edu:/home/julian/embl/paper/storage/EVGT7MP7/Agresti and Coull - 1998 - Approximate is better than {\textquotedblleft}exact{\textquotedblright} for interval es.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/5PH42S4W/cookieAbsent.html:text/html}
}

@article{agresti_unconditional_2002,
	title = {Unconditional small-sample confidence intervals for the odds ratio},
	volume = {3},
	issn = {1465-4644, 1468-4357},
	url = {http://biostatistics.oxfordjournals.org/content/3/3/379},
	doi = {10.1093/biostatistics/3.3.379},
	abstract = {The traditional approach to {\textquoteleft}exact{\textquoteright} small-sample interval estimation of the odds ratio for binomial, Poisson, or multinomial samples uses the conditional distribution to eliminate nuisance parameters. This approach can be very conservative. For two independent binomial samples, we study an unconditional approach with overall confidence level guaranteed to equal at least the nominal level. With small samples this interval tends to be shorter and have coverage probabilities nearer the nominal level.},
	language = {en},
	number = {3},
	urldate = {2013-12-09},
	journal = {Biostatistics},
	author = {Agresti, Alan and Min, Yongyi},
	month = sep,
	year = {2002},
	note = {{PMID:} 12933604},
	keywords = {Binomial distribution, Conditional tests, Exact inference, Two-by-two contingency table},
	pages = {379--386},
	file = {Full Text PDF:/home/julian/embl/paper/storage/39K4HTRQ/Agresti and Min - 2002 - Unconditional small-sample confidence intervals fo.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/7HCEDMC4/379.html:text/html}
}

@article{benjamini_false_2005,
	title = {False discovery rate{\textendash}adjusted multiple confidence intervals for selected parameters},
	volume = {100},
	url = {http://amstat.tandfonline.com/doi/abs/10.1198/016214504000001907},
	number = {469},
	urldate = {2013-12-10},
	journal = {Journal of the American Statistical Association},
	author = {Benjamini, Yoav and Yekutieli, Daniel},
	year = {2005},
	pages = {71{\textendash}81},
	file = {[PDF] von tau.ac.il:/home/julian/embl/paper/storage/IS2TRBKV/Benjamini and Yekutieli - 2005 - False discovery rate{\textendash}adjusted multiple confidence .pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/J6977TD5/cookieAbsent.html:text/html}
}

@article{decrouez_split_2013,
	title = {Split sample methods for constructing confidence intervals for binomial and Poisson parameters},
	copyright = {{\textcopyright} 2013 Royal Statistical Society},
	issn = {1467-9868},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/rssb.12051/abstract},
	doi = {10.1111/rssb.12051},
	abstract = {We introduce a new method for improving the coverage accuracy of confidence intervals for means of lattice distributions. The technique can be applied very generally to enhance existing approaches, although we consider it in greatest detail in the context of estimating a binomial proportion or a Poisson mean, where it is particularly effective. The method is motivated by a simple theoretical result, which shows that, by splitting the original sample of size n into two parts, of sizes n1 and n2=n-n1, and basing the confidence procedure on the average of the means of these two subsamples, the highly oscillatory behaviour of coverage error, as a function of n, is largely removed. Perhaps surprisingly, this approach does not increase confidence interval width; usually the width is slightly reduced. Contrary to what might be expected, our new method performs well when it is used to modify confidence intervals based on existing techniques that already perform very well{\textemdash}it typically improves significantly their coverage accuracy. Each application of the split sample method to an existing confidence interval procedure results in a new technique.},
	language = {en},
	urldate = {2014-03-05},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Decrouez, Geoffrey and Hall, Peter},
	year = {2013},
	keywords = {Asymptotic expansion, Bootstrap, Coverage accuracy, Interval length, One-sided intervals, Two-sided intervals},
	pages = {n/a{\textendash}n/a},
	file = {Decrouez and Hall - 2013 - Split sample methods for constructing confidence i.pdf:/home/julian/embl/paper/storage/FBG667SQ/Decrouez and Hall - 2013 - Split sample methods for constructing confidence i.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/XJRZFMVV/abstract.html:text/html}
}

@article{fagerland_recommended_2011,
	title = {Recommended confidence intervals for two independent binomial proportions},
	url = {http://smm.sagepub.com/content/early/2011/10/11/0962280211415469.abstract},
	urldate = {2013-12-13},
	journal = {Statistical methods in medical research},
	author = {Fagerland, Morten W. and Lydersen, Stian and Laake, Petter},
	year = {2011},
	file = {[PDF] von researchgate.net:/home/julian/embl/paper/storage/APAZ4J6N/Fagerland et al. - 2011 - Recommended confidence intervals for two independe.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/89CXUBJK/0962280211415469.html:text/html}
}

@article{farrington_test_1990,
	title = {Test statistics and sample size formulae for comparative binomial trials with null hypothesis of non-zero risk difference or non-unity relative risk},
	volume = {9},
	copyright = {Copyright {\textcopyright} 1990 John Wiley \& Sons, Ltd.},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.4780091208/abstract},
	doi = {10.1002/sim.4780091208},
	abstract = {When it is required to establish a materially significant difference between two treatments, or, alternatively, to show that two treatments are equivalent, standard test statistics and sample size formulae based on a null hypothesis of no difference no longer apply. This paper reviews some of the test statistics and sample size formulae proposed for comparative binomial trials when the null hypothesis is of a specified non-zero difference or non-unity relative risk. Methods based on restricted maximum likelihood estimation are recommended and applied to studies of pertussis vaccine.},
	language = {en},
	number = {12},
	urldate = {2014-01-22},
	journal = {Statistics in Medicine},
	author = {Farrington, Conor P. and Manning, Godfrey},
	year = {1990},
	pages = {1447{\textendash}1454},
	file = {Full Text PDF:/home/julian/embl/paper/storage/4CMRVWI5/Farrington and Manning - 1990 - Test statistics and sample size formulae for compa.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/ZAB3X7AA/full.html:text/html}
}

@book{fleiss_statistical_2013,
	title = {Statistical methods for rates and proportions},
	url = {http://books.google.de/books?hl=de&lr=&id=9VefO7a8GeAC&oi=fnd&pg=PT13&dq=Interval+Estimation+for+the+Difference+Between+Independent+Proportions&ots=po7iNMzBKT&sig=eSFnYXR3AbF3F4BbxIWpGfDUFHM},
	urldate = {2013-12-12},
	publisher = {John Wiley \& Sons},
	author = {Fleiss, Joseph L. and Levin, Bruce and Paik, Myunghee Cho},
	year = {2013},
	file = {Snapshot:/home/julian/embl/paper/storage/F3SFTKRD/books.html:text/html}
}

@article{gerstung_reliable_2012,
	title = {Reliable detection of subclonal single-nucleotide variants in tumour cell populations},
	volume = {3},
	copyright = {{\textcopyright} 2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	url = {http://www.nature.com/ncomms/journal/v3/n5/full/ncomms1814.html},
	doi = {10.1038/ncomms1814},
	abstract = {According to the clonal evolution model, tumour growth is driven by competing subclones in somatically evolving cancer cell populations, which gives rise to genetically heterogeneous tumours. Here we present a comparative targeted deep-sequencing approach combined with a customised statistical algorithm, called {deepSNV}, for detecting and quantifying subclonal single-nucleotide variants in mixed populations. We show in a rigorous experimental assessment that our approach is capable of detecting variants with frequencies as low as 1/10,000 alleles. In selected genomic loci of the {TP53} and {VHL} genes isolated from matched tumour and normal samples of four renal cell carcinoma patients, we detect 24 variants at allele frequencies ranging from 0.0002 to 0.34. Moreover, we demonstrate how the allele frequencies of known single-nucleotide polymorphisms can be exploited to detect loss of heterozygosity. Our findings demonstrate that genomic diversity is common in renal cell carcinomas and provide quantitative evidence for the clonal evolution model.},
	language = {en},
	urldate = {2013-08-06},
	journal = {Nature Communications},
	author = {Gerstung, Moritz and Beisel, Christian and Rechsteiner, Markus and Wild, Peter and Schraml, Peter and Moch, Holger and Beerenwinkel, Niko},
	month = may,
	year = {2012},
	keywords = {bioinformatics, Biological sciences, Cancer, genetics},
	pages = {811},
	file = {Gerstung et al. - 2012 - Reliable detection of subclonal single-nucleotide .pdf:/home/julian/embl/paper/storage/66U58XV6/Gerstung et al. - 2012 - Reliable detection of subclonal single-nucleotide .pdf:application/pdf;GerstungNC2012a.pdf:/home/julian/embl/paper/storage/7KM8FZKR/GerstungNC2012a.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/JGCXJSND/ncomms1814.html:text/html}
}

@article{gerstung_subclonal_2014,
	title = {Subclonal variant calling with multiple samples and prior knowledge},
	issn = {1367-4803, 1460-2059},
	url = {http://bioinformatics.oxfordjournals.org/content/early/2014/01/16/bioinformatics.btt750},
	doi = {10.1093/bioinformatics/btt750},
	abstract = {Motivation: Targeted resequencing of cancer genes in large cohorts of patients is important to understand the biological and clinical consequences of mutations. Cancers are often clonally heterogeneous and the detection of subclonal mutations is important from a diagnostic point of view, but presents strong statistical challenges.
Results: Here we present a novel statistical approach for calling mutations from large cohorts of deeply resequenced cancer genes. These data allow for precisely estimating local error profiles and enable detecting mutations with high sensitivity and specificity. Our probabilistic method incorporates knowledge about the distribution of variants in terms of a prior probability. We show that our algorithm has a high accuracy of calling cancer mutations and demonstrate that the detected clonal and subclonal variants have important prognostic consequences.
Availability: Code is available as part of the Bioconductor package {deepSNV.}
Contact: mg14@sanger.ac.uk, pc8@sanger.ac.uk},
	language = {en},
	urldate = {2014-01-28},
	journal = {Bioinformatics},
	author = {Gerstung, Moritz and Papaemmanuil, Elli and Campbell, Peter J.},
	month = jan,
	year = {2014},
	note = {{PMID:} 24443148},
	pages = {btt750},
	file = {Full Text PDF:/home/julian/embl/paper/storage/9TN9VU38/Gerstung et al. - 2014 - Subclonal variant calling with multiple samples an.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/WF3CV5BW/bioinformatics.btt750.html:text/html}
}

@article{jung_reporting_2011,
	title = {Reporting {FDR} analogous confidence intervals for the log fold change of differentially expressed genes},
	volume = {12},
	copyright = {2011 Jung et al; licensee {BioMed} Central Ltd.},
	issn = {1471-2105},
	url = {http://www.biomedcentral.com/1471-2105/12/288/abstract},
	doi = {10.1186/1471-2105-12-288},
	abstract = {Gene expression experiments are common in molecular biology, for example in order to identify genes which play a certain role in a specified biological framework. For that purpose expression levels of several thousand genes are measured simultaneously using {DNA} microarrays. Comparing two distinct groups of tissue samples to detect those genes which are differentially expressed one statistical test per gene is performed, and resulting p-values are adjusted to control the false discovery rate. In addition, the expression change of each gene is quantified by some effect measure, typically the log fold change. In certain cases, however, a gene with a significant p-value can have a rather small fold change while in other cases a non-significant gene can have a rather large fold change. The biological relevance of the change of gene expression can be more intuitively judged by a fold change then merely by a p-value. Therefore, confidence intervals for the log fold change which accompany the adjusted p-values are desirable.
{PMID:} 21756370},
	language = {en},
	number = {1},
	urldate = {2013-12-10},
	journal = {{BMC} Bioinformatics},
	author = {Jung, Klaus and Friede, Tim and Bei{\ss}barth, Tim},
	month = jul,
	year = {2011},
	note = {{PMID:} 21756370},
	pages = {288},
	file = {Full Text PDF:/home/julian/embl/paper/storage/8UXXIBWJ/Jung et al. - 2011 - Reporting FDR analogous confidence intervals for t.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/VS7AMKEQ/288.html:text/html}
}

@article{kim_comparing_2013,
	title = {Comparing somatic mutation-callers: beyond Venn diagrams},
	volume = {14},
	copyright = {2013 Kim and Speed; licensee {BioMed} Central Ltd.},
	issn = {1471-2105},
	shorttitle = {Comparing somatic mutation-callers},
	url = {http://www.biomedcentral.com/1471-2105/14/189/abstract},
	doi = {10.1186/1471-2105-14-189},
	abstract = {Somatic mutation-calling based on {DNA} from matched tumor-normal patient samples is one of the key tasks carried by many cancer genome projects. One such large-scale project is The Cancer Genome Atlas ({TCGA)}, which is now routinely compiling catalogs of somatic mutations from hundreds of paired tumor-normal {DNA} exome-sequence data. Nonetheless, mutation calling is still very challenging. {TCGA} benchmark studies revealed that even relatively recent mutation callers from major centers showed substantial discrepancies. Evaluation of the mutation callers or understanding the sources of discrepancies is not straightforward, since for most tumor studies, validation data based on independent whole-exome {DNA} sequencing is not available, only partial validation data for a selected (ascertained) subset of sites.},
	language = {en},
	number = {1},
	urldate = {2013-08-31},
	journal = {{BMC} Bioinformatics},
	author = {Kim, Su Y. and Speed, Terence P.},
	month = jun,
	year = {2013},
	note = {{PMID:} 23758877},
	keywords = {Cancer genome, Methods comparison, next-generation sequencing, Somatic mutation-calling, Validation},
	pages = {189},
	file = {Full Text PDF:/home/julian/embl/paper/storage/59XKSD3D/Kim and Speed - 2013 - Comparing somatic mutation-callers beyond Venn di.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/WNWBQB85/189.html:text/html}
}

@article{knol_misuse_2011,
	title = {The (mis)use of overlap of confidence intervals to assess effect modification},
	volume = {26},
	issn = {0393-2990},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3088813/},
	doi = {10.1007/s10654-011-9563-8},
	number = {4},
	urldate = {2014-01-10},
	journal = {European Journal of Epidemiology},
	author = {Knol, Mirjam J. and Pestman, Wiebe R. and Grobbee, Diederick E.},
	month = apr,
	year = {2011},
	note = {{PMID:} 21424218
{PMCID:} {PMC3088813}},
	pages = {253--254},
	file = {PubMed Central Full Text PDF:/home/julian/embl/paper/storage/JBAQ3BXE/Knol et al. - 2011 - The (mis)use of overlap of confidence intervals to.pdf:application/pdf}
}

@article{koopman_confidence_1984,
	title = {Confidence Intervals for the Ratio of Two Binomial Proportions},
	volume = {40},
	issn = {{0006341X}},
	url = {http://www.jstor.org/discover/10.2307/2531405?uid=23537&uid=3737864&uid=2&uid=3&uid=23528&uid=67&uid=62&sid=21103093065887},
	doi = {10.2307/2531405},
	number = {2},
	urldate = {2013-12-09},
	journal = {Biometrics},
	author = {Koopman, P. A. R.},
	month = jun,
	year = {1984},
	pages = {513},
	file = {JSTOR: Biometrics, Vol. 40, No. 2 (Jun., 1984), pp. 513-517:/home/julian/embl/paper/storage/35IH753W/2531405.html:text/html}
}

@article{leung_quick_2014,
	title = {Quick, sensitive and specific detection and evaluation of quantification of minor variants by high-throughput sequencing},
	issn = {1742-{206X}, 1742-2051},
	url = {http://xlink.rsc.org/?DOI=c3mb70334g},
	doi = {10.1039/c3mb70334g},
	urldate = {2013-12-17},
	journal = {Molecular {BioSystems}},
	author = {Leung, Ross Ka-Kit and Dong, Zhi Qiang and Sa, Fei and Chong, Cheong Meng and Lei, Si Wan and Tsui, Stephen Kwok-Wing and Lee, Simon Ming-Yuen},
	year = {2014}
}

@article{miettinen_comparative_1985,
	title = {Comparative analysis of two rates},
	volume = {4},
	copyright = {Copyright {\textcopyright} 1985 John Wiley \& Sons, Ltd.},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.4780040211/abstract},
	doi = {10.1002/sim.4780040211},
	abstract = {In this paper, we examine comparative analysis of rates with a view to each of the usual comparative parameters-rate difference ({RD)}, rate ratio ({RR)} and odds ratio ({OR)-and} with particular reference to first principles. For {RD} and {RR} we show the prevailing statistical practices to be rather poor. We stress the need for restricted estimation of variance in the chi-square function underlying interval estimation (and also point estimation and hypothesis testing). For {RR} analysis we propose a chi-square formulation analogous to that for {RD} and, thus, one which obviates the present practice of log transformation and its associated use of Taylor series approximation of the variance. As for {OR} analysis, we emphasize that the chi-square function, introduced by Cornfield for unstratified data, and extended by Gart to the case of stratified analysis, is based on the efficient score and thus embodies its optimality properties. We provide simulation results to evince the better performance of the proposed (parameter-constrained) procedures over the traditional ones.},
	language = {en},
	number = {2},
	urldate = {2013-12-09},
	journal = {Statistics in Medicine},
	author = {Miettinen, Olli and Nurminen, Markku},
	year = {1985},
	keywords = {Asymptotic confidence intervals, Biometry, Constrained maximum likelihood estimation Epidemiologic methods},
	pages = {213{\textendash}226},
	file = {Full Text PDF:/home/julian/embl/paper/storage/6D8BV89K/Miettinen and Nurminen - 1985 - Comparative analysis of two rates.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/AXUQDX38/full.html:text/html}
}

@article{muralidharan_detecting_2012,
	title = {Detecting mutations in mixed sample sequencing data using empirical Bayes},
	volume = {6},
	issn = {1932-6157, 1941-7330},
	url = {http://projecteuclid.org/euclid.aoas/1346418573},
	doi = {10.1214/12-AOAS538},
	abstract = {We develop statistically based methods to detect single nucleotide {DNA} mutations in next generation sequencing data. Sequencing generates counts of the number of times each base was observed at hundreds of thousands to billions of genome positions in each sample. Using these counts to detect mutations is challenging because mutations may have very low prevalence and sequencing error rates vary dramatically by genome position. The discreteness of sequencing data also creates a difficult multiple testing problem: current false discovery rate methods are designed for continuous data, and work poorly, if at all, on discrete data. We show that a simple randomization technique lets us use continuous false discovery rate methods on discrete data. Our approach is a useful way to estimate false discovery rates for any collection of discrete test statistics, and is hence not limited to sequencing data. We then use an empirical Bayes model to capture different sources of variation in sequencing error rates. The resulting method outperforms existing detection approaches on example data sets.},
	language = {{EN}},
	number = {3},
	urldate = {2014-03-31},
	journal = {The Annals of Applied Statistics},
	author = {Muralidharan, Omkar and Natsoulis, Georges and Bell, John and Ji, Hanlee and Zhang, Nancy R.},
	month = sep,
	year = {2012},
	note = {Zentralblatt {MATH} identifier06096521, Mathematical Reviews number ({MathSciNet)} {MR3012520}},
	keywords = {discrete data, {DNA} sequencing, Empirical Bayes, false discovery rates, genome variation},
	pages = {1047--1067},
	file = {1209.6453 PDF:/home/julian/embl/paper/storage/4PCCI65Z/Muralidharan et al. - 2012 - Detecting mutations in mixed sample sequencing dat.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/67UNE7T8/1346418573.html:text/html}
}

@article{newcombe_improved_1998,
	title = {Improved confidence intervals for the difference between binomial proportions based on paired data},
	volume = {17},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.8637&rep=rep1&type=pdf},
	number = {22},
	urldate = {2013-12-12},
	journal = {Statistics in medicine},
	author = {Newcombe, Robert G.},
	year = {1998},
	pages = {2635{\textendash}2650},
	file = {[PDF] von psu.edu:/home/julian/embl/paper/storage/GA2KVWSM/Newcombe - 1998 - Improved confidence intervals for the difference b.pdf:application/pdf}
}

@article{newcombe_interval_1998,
	title = {Interval estimation for the difference between independent proportions: comparison of eleven methods},
	volume = {17},
	shorttitle = {Interval estimation for the difference between independent proportions},
	url = {http://www.researchgate.net/publication/13687790_Interval_estimation_for_the_difference_between_independent_proportions_comparison_of_eleven_methods/file/32bfe50f467c856bcc.pdf},
	number = {8},
	urldate = {2013-12-12},
	journal = {Statistics in medicine},
	author = {Newcombe, Robert G.},
	year = {1998},
	pages = {873{\textendash}890},
	file = {[PDF] von researchgate.net:/home/julian/embl/paper/storage/88NGPCSC/Newcombe - 1998 - Interval estimation for the difference between ind.pdf:application/pdf}
}

@article{newcombe_two-sided_1998,
	title = {Two-sided confidence intervals for the single proportion: comparison of seven methods},
	volume = {17},
	shorttitle = {Two-sided confidence intervals for the single proportion},
	url = {http://www.nucmed.com/documents/Academic/Grants/GBM_SVM_BN/Articles/Two-Sided%20Confidence%20Intervals%20for%20the%20Single%20Proportion.pdf},
	number = {8},
	urldate = {2013-12-12},
	journal = {Statistics in medicine},
	author = {Newcombe, Robert G.},
	year = {1998},
	pages = {857{\textendash}872},
	file = {[PDF] von nucmed.com:/home/julian/embl/paper/storage/IIV8BCBD/Newcombe - 1998 - Two-sided confidence intervals for the single prop.pdf:application/pdf}
}

@article{nurminen_exact_1987,
	title = {Exact Bayesian analysis of two proportions},
	url = {http://www.jstor.org/stable/10.2307/4616049},
	urldate = {2013-12-09},
	journal = {Scandinavian Journal of Statistics},
	author = {Nurminen, Markku and Mutanen, Pertti},
	year = {1987},
	pages = {67{\textendash}77},
	file = {[PDF] von researchgate.net:/home/julian/embl/paper/storage/KDXHUJ54/Nurminen and Mutanen - 1987 - Exact Bayesian analysis of two proportions.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/57HGT2NU/cookieAbsent.html:text/html}
}

@article{piegorsch_sample_2004,
	title = {Sample sizes for improved binomial confidence intervals},
	volume = {46},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947303002354},
	doi = {10.1016/j.csda.2003.10.002},
	abstract = {Sample size equations are reviewed for different types of confidence intervals on a binomial success probability. Based on recommendations for improved binomial confidence limits given by Brown et al. (Statist. Sci. 16 (2001) 101), the intervals expand upon or enhance the traditional Wald-type interval. Some useful sample size relations appear.},
	number = {2},
	urldate = {2013-12-10},
	journal = {Computational Statistics \& Data Analysis},
	author = {Piegorsch, Walter W.},
	month = jun,
	year = {2004},
	keywords = {{Agresti{\textendash}Coull} interval, Binomial probability, Jeffreys interval, Sample size determination, Score interval, Wald interval, Wilson interval},
	pages = {309--316},
	file = {ScienceDirect Full Text PDF:/home/julian/embl/paper/storage/7RKU4R78/Piegorsch - 2004 - Sample sizes for improved binomial confidence inte.pdf:application/pdf;ScienceDirect Snapshot:/home/julian/embl/paper/storage/HCTJENI4/S0167947303002354.html:text/html}
}

@misc{pyl_h5vcdata:_2013,
	title = {{h5vcData:} Example data for the h5vc package},
	url = {http://bioconductor.org/packages/release/data/experiment/html/h5vcData.html},
	author = {Pyl, Paul Theodor},
	year = {2013}
}

@misc{pyl_h5vc:_2013,
	title = {h5vc: Managing alignment tallies using a hdf5 backend},
	url = {http://bioconductor.org/packages/release/bioc/html/h5vc.html},
	author = {Pyl, Paul Theodor},
	year = {2013}
}

@article{pyl_h5vc:_2014,
	title = {h5vc: Scalable nucleotide tallies with {HDF5}},
	issn = {1367-4803, 1460-2059},
	shorttitle = {h5vc},
	url = {http://bioinformatics.oxfordjournals.org/content/early/2014/01/21/bioinformatics.btu026},
	doi = {10.1093/bioinformatics/btu026},
	abstract = {Summary: As applications of genome sequencing including exomes and whole genomes are expanding, there is a need for analysis tools that are scalable to large sets of samples and/or ultra-deep coverage. Many current tool chains are based on the widely used file formats {BAM} (Li et al. (2009)) and {VCF} or {VCF-derivatives} (Danecek et al. (2011); Purcell et al. (2007)). However, for some desirable analyses, data management with these formats creates substantial implementation overhead, and much time is spent parsing files and collating data. We observe that a tally data structure, i. e. the table of counts of nucleotides x samples x strands x genomic positions, provides a reasonable intermediate level of abstraction for many genomics analyses, including variant calling ({SNVs} and {InDels)}, copy-number estimation, mutation spectrum analysis. Here we present h5vc, a data structure and associated software for managing tallies. The software contains functionality for creating tallies from {BAM} files, flexible and scalable data visualisation, data quality assessment, computing statistics relevant to variant calling and other applications. Through the simplicity of its {API}, we envision making low-level analysis of large sets of genome sequencing data accessible to a wider range of researchers.
Availability and Implementation: The package h5vc for the statistical environment R is available through the Bioconductor project (Gentleman et al. (2004)). The {HDF5} system (The {HDF} Group (2010)) is used as the core of our implementation.
Contact: pyl@embl.de},
	language = {en},
	urldate = {2014-01-30},
	journal = {Bioinformatics},
	author = {Pyl, Paul Theodor and Gehring, Julian and Fischer, Bernd and Huber, Wolfgang},
	month = jan,
	year = {2014},
	note = {{PMID:} 24451629},
	pages = {btu026},
	file = {Full Text PDF:/home/julian/embl/paper/storage/AZ7U3AW5/Pyl et al. - 2014 - h5vc Scalable nucleotide tallies with HDF5.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/9XFMSWDZ/bioinformatics.html:text/html}
}

@article{roberts_comparative_2013,
	title = {A comparative analysis of algorithms for somatic {SNV} detection in cancer},
	volume = {29},
	issn = {1367-4803, 1460-2059},
	url = {http://bioinformatics.oxfordjournals.org/content/29/18/2223},
	doi = {10.1093/bioinformatics/btt375},
	abstract = {Motivation: With the advent of relatively affordable high-throughput technologies, {DNA} sequencing of cancers is now common practice in cancer research projects and will be increasingly used in clinical practice to inform diagnosis and treatment. Somatic (cancer-only) single nucleotide variants ({SNVs)} are the simplest class of mutation, yet their identification in {DNA} sequencing data is confounded by germline polymorphisms, tumour heterogeneity and sequencing and analysis errors. Four recently published algorithms for the detection of somatic {SNV} sites in matched cancer{\textendash}normal sequencing datasets are {VarScan}, {SomaticSniper}, {JointSNVMix} and Strelka. In this analysis, we apply these four {SNV} calling algorithms to cancer{\textendash}normal Illumina exome sequencing of a chronic myeloid leukaemia ({CML)} patient. The candidate {SNV} sites returned by each algorithm are filtered to remove likely false positives, then characterized and compared to investigate the strengths and weaknesses of each {SNV} calling algorithm.
Results: Comparing the candidate {SNV} sets returned by {VarScan}, {SomaticSniper}, {JointSNVMix2} and Strelka revealed substantial differences with respect to the number and character of sites returned; the somatic probability scores assigned to the same sites; their susceptibility to various sources of noise; and their sensitivities to low-allelic-fraction candidates.
Availability: Data accession number {SRA081939}, code at http://code.google.com/p/snv-caller-review/
Contact: david.adelson@adelaide.edu.au
Supplementary information: Supplementary data are available at Bioinformatics online.},
	language = {en},
	number = {18},
	urldate = {2013-08-27},
	journal = {Bioinformatics},
	author = {Roberts, Nicola D. and Kortschak, R. Daniel and Parker, Wendy T. and Schreiber, Andreas W. and Branford, Susan and Scott, Hamish S. and Glonek, Garique and Adelson, David L.},
	month = sep,
	year = {2013},
	note = {{PMID:} 23842810},
	pages = {2223--2230},
	file = {Full Text PDF:/home/julian/embl/paper/storage/ZQ8AFHS4/Roberts et al. - 2013 - A comparative analysis of algorithms for somatic S.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/28KFEDPC/2223.abstract.html:text/html}
}

@misc{schaarschmidt_mcpan:_2013,
	title = {{MCPAN:} Multiple comparisons using normal approximation},
	copyright = {{GPL-2}},
	shorttitle = {{MCPAN}},
	url = {http://cran.r-project.org/web/packages/MCPAN/index.html},
	abstract = {Multiple contrast tests and simultaneous confidence
intervals based on normal approximation. With implementations for
binomial proportions in a 2xk setting (risk difference and odds ratio),
poly-3-adjusted tumour rates, biodiversity indices (multinomial data)
and expected values under lognormal assumption. Approximative power
calculation for multiple contrast tests of binomial and Gaussian data.},
	urldate = {2014-01-08},
	author = {Schaarschmidt, Frank and Gerhard, Daniel and Sill, Martin},
	month = oct,
	year = {2013},
	file = {R Package Snapshot:/home/julian/embl/paper/storage/JCGDAMSU/index.html:text/html}
}

@article{schaarschmidt_approximate_2008,
	title = {Approximate Simultaneous Confidence Intervals for Multiple Contrasts of Binomial Proportions},
	volume = {50},
	copyright = {Copyright {\textcopyright} 2008 {WILEY-VCH} Verlag {GmbH} \& Co. {KGaA}, Weinheim},
	issn = {1521-4036},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/bimj.200710465/abstract},
	doi = {10.1002/bimj.200710465},
	abstract = {Simultaneous confidence intervals for contrasts of means in a one-way layout with several independent samples are well established for Gaussian distributed data. Procedures addressing different hypotheses are available, such as all pairwise comparisons or comparisons to control, comparison with average, or different tests for order-restricted alternatives. However, if the distribution of the response is not Gaussian, corresponding methods are usually not available or not implemented in software. For the case of comparisons among several binomial proportions, we extended recently proposed confidence interval methods for the difference of two proportions or single contrasts to multiple contrasts by using quantiles of the multivariate normal distribution, taking the correlation into account. The small sample performance of the proposed methods was investigated in simulation studies. The simple adjustment of adding 2 pseudo-observations to each sample estimate leads to reasonable coverage probabilities. The methods are illustrated by the evaluation of real data examples of a clinical trial and a toxicological study. The proposed methods and examples are available in the R package {MCPAN.} ({\textcopyright} 2008 {WILEY-VCH} Verlag {GmbH} \& Co. {KGaA}, Weinheim)},
	language = {en},
	number = {5},
	urldate = {2014-01-08},
	journal = {Biometrical Journal},
	author = {Schaarschmidt, Frank and Sill, Martin and Hothorn, Ludwig A.},
	year = {2008},
	keywords = {Multiple inference, Multivariate normal, Simple adjustment, Small sample},
	pages = {782{\textendash}792},
	file = {Snapshot:/home/julian/embl/paper/storage/HHU3HNCN/abstract;jsessionid=D56FDB59BACA59840C96087C236FCBE5.html:text/html}
}

@article{shiraishi_empirical_2013,
	title = {An empirical Bayesian framework for somatic mutation detection from cancer genome sequencing data},
	issn = {0305-1048, 1362-4962},
	url = {http://nar.oxfordjournals.org/content/early/2013/03/06/nar.gkt126},
	doi = {10.1093/nar/gkt126},
	abstract = {Recent advances in high-throughput sequencing technologies have enabled a comprehensive dissection of the cancer genome clarifying a large number of somatic mutations in a wide variety of cancer types. A number of methods have been proposed for mutation calling based on a large amount of sequencing data, which is accomplished in most cases by statistically evaluating the difference in the observed allele frequencies of possible single nucleotide variants between tumours and paired normal samples. However, an accurate detection of mutations remains a challenge under low sequencing depths or tumour contents. To overcome this problem, we propose a novel method, Empirical Bayesian mutation Calling ({https://github.com/friend1ws/EBCall)}, for detecting somatic mutations. Unlike previous methods, the proposed method discriminates somatic mutations from sequencing errors based on an empirical Bayesian framework, where the model parameters are estimated using sequencing data from multiple non-paired normal samples. Using 13 whole-exome sequencing data with 87.5{\textendash}206.3 mean sequencing depths, we demonstrate that our method not only outperforms several existing methods in the calling of mutations with moderate allele frequencies but also enables accurate calling of mutations with low allele frequencies (<=10\%) harboured within a minor tumour subpopulation, thus allowing for the deciphering of fine substructures within a tumour specimen.},
	language = {en},
	urldate = {2014-02-05},
	journal = {Nucleic Acids Research},
	author = {Shiraishi, Yuichi and Sato, Yusuke and Chiba, Kenichi and Okuno, Yusuke and Nagata, Yasunobu and Yoshida, Kenichi and Shiba, Norio and Hayashi, Yasuhide and Kume, Haruki and Homma, Yukio and Sanada, Masashi and Ogawa, Seishi and Miyano, Satoru},
	month = mar,
	year = {2013},
	note = {{PMID:} 23471004},
	pages = {gkt126},
	file = {Full Text PDF:/home/julian/embl/paper/storage/2EXV7KGV/Shiraishi et al. - 2013 - An empirical Bayesian framework for somatic mutati.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/CKQQ9PHU/nar.gkt126.html:text/html}
}

@article{simon_estimating_2013,
	title = {On Estimating Many Means, Selection Bias, and the Bootstrap},
	url = {http://arxiv.org/abs/1311.3709},
	urldate = {2013-12-10},
	journal = {{arXiv} preprint {arXiv:1311.3709}},
	author = {Simon, Noah and Simon, Richard},
	year = {2013},
	file = {[PDF] von arxiv.org:/home/julian/embl/paper/storage/FK5IQGFU/Simon and Simon - 2013 - On Estimating Many Means, Selection Bias, and the .pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/BMNVMD72/1311.html:text/html}
}

@article{the_1000_genomes_project_consortium_map_2010,
	title = {A map of human genome variation from population-scale sequencing},
	volume = {467},
	issn = {0028-0836},
	url = {http://www.nature.com/nature/journal/v467/n7319/full/nature09534.html},
	doi = {10.1038/nature09534},
	abstract = {The 1000 Genomes Project aims to provide a deep characterization of human genome sequence variation as a foundation for investigating the relationship between genotype and phenotype. Here we present results of the pilot phase of the project, designed to develop and compare different strategies for genome-wide sequencing with high-throughput platforms. We undertook three projects: low-coverage whole-genome sequencing of 179 individuals from four populations; high-coverage sequencing of two mother{\textendash}father{\textendash}child trios; and exon-targeted sequencing of 697 individuals from seven populations. We describe the location, allele frequency and local haplotype structure of approximately 15 million single nucleotide polymorphisms, 1 million short insertions and deletions, and 20,000 structural variants, most of which were previously undescribed. We show that, because we have catalogued the vast majority of common variation, over 95\% of the currently accessible variants found in any individual are present in this data set. On average, each person is found to carry approximately 250 to 300 loss-of-function variants in annotated genes and 50 to 100 variants previously implicated in inherited disorders. We demonstrate how these results can be used to inform association and functional studies. From the two trios, we directly estimate the rate of de novo germline base substitution mutations to be approximately 10-8 per base pair per generation. We explore the data with regard to signatures of natural selection, and identify a marked reduction of genetic variation in the neighbourhood of genes, due to selection at linked sites. These methods and public data will support the next phase of human genetic research.},
	language = {en},
	number = {7319},
	urldate = {2013-12-26},
	journal = {Nature},
	author = {{The 1000 Genomes Project Consortium}},
	month = oct,
	year = {2010},
	keywords = {Genetics and genomics},
	pages = {1061--1073},
	file = {Full Text PDF:/home/julian/embl/paper/storage/IT2BFQVP/Consortium - 2010 - A map of human genome variation from population-sc.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/3KF5IJUW/nature09534.html:text/html}
}

@article{thulin_split_2014,
	title = {On split sample and randomized confidence intervals for binomial proportions},
	url = {http://arxiv.org/abs/1402.6536},
	abstract = {Split sample methods have recently been put forward as a way to reduce the coverage oscillations that haunt confidence intervals for parameters of lattice distributions, such as the binomial and Poisson distributions. We study split sample intervals in the binomial setting, showing that these intervals can be viewed as being based on adding discrete random noise to the data. It is shown that they can be improved upon by using noise with a continuous distribution instead, regardless of whether the randomization is determined by the data or an external source of randomness. We compare split sample intervals to the randomized Stevens interval, which removes the coverage oscillations completely, and find the latter interval to have several advantages.},
	urldate = {2014-03-04},
	journal = {{arXiv:1402.6536} [stat]},
	author = {Thulin, M{\r a}ns},
	month = feb,
	year = {2014},
	keywords = {Statistics - Methodology}
}

@article{tibshirani_adaptive_2013,
	title = {Adaptive Piecewise Polynomial Estimation via Trend Filtering},
	url = {http://arxiv.org/abs/1304.2986},
	abstract = {We study trend filtering, a recently proposed tool of Kim et al. (2009) for nonparametric regression. The trend filtering estimate is defined as the minimizer of a penalized least squares criterion, in which the penalty term sums the absolute kth order discrete derivatives over the input points. Perhaps not surprisingly, trend filtering estimates appear to have the structure of kth degree spline functions, with adaptively chosen knot points (we say "appear" here as trend filtering estimates are not really functions over continuous domains, and are only defined over the discrete set of inputs). This brings to mind comparisons to other nonparametric regression tools that also produce adaptive splines; in particular, we compare trend filtering to smoothing splines, which penalize the sum of squared derivatives across input points, and to locally adaptive regression splines (Mammen \& van de Geer 1997), which penalize the total variation of the kth derivative. Empirically, we discover that trend filtering estimates adapt to the local level of smoothness much better than smoothing splines, and further, they exhibit a remarkable similarity to locally adaptive regression splines. We also provide theoretical support for these empirical findings; most notably, we prove that (with the right choice of tuning parameter) the trend filtering estimate converges to the true underlying function at the minimax rate for functions whose kth derivative is of bounded variation. This is done via an asymptotic pairing of trend filtering and locally adaptive regression splines, which have already been shown to converge at the minimax rated (Mammen \& van de Geer 1997). At the core of this argument is a new result tying together the fitted values of two lasso problems that share the same outcome vector, but have different predictor matrices.},
	urldate = {2014-02-12},
	journal = {{arXiv:1304.2986} [math, stat]},
	author = {Tibshirani, Ryan J.},
	month = apr,
	year = {2013},
	keywords = {Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Methodology}
}

@article{wang_exactcidiff:_2013,
	title = {{ExactCIdiff:} An R Package for Computing Exact Confidence Intervals for the Difference of Two Proportions},
	volume = {5},
	url = {http://journal.r-project.org/archive/2013-2/wang-shan.pdf},
	number = {2},
	journal = {The R Journal},
	author = {Wang, Weizhen and Shan, Guogen},
	month = dec,
	year = {2013},
	pages = {62{\textendash}71},
	file = {wang-shan.pdf:/home/julian/embl/paper/storage/E5QFSESS/wang-shan.pdf:application/pdf}
}

@article{wilm_lofreq:_2012,
	title = {{LoFreq:} a sequence-quality aware, ultra-sensitive variant caller for uncovering cell-population heterogeneity from high-throughput sequencing datasets},
	volume = {40},
	issn = {0305-1048},
	shorttitle = {{LoFreq}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3526318/},
	doi = {10.1093/nar/gks918},
	abstract = {The study of cell-population heterogeneity in a range of biological systems, from viruses to bacterial isolates to tumor samples, has been transformed by recent advances in sequencing throughput. While the high-coverage afforded can be used, in principle, to identify very rare variants in a population, existing ad hoc approaches frequently fail to distinguish true variants from sequencing errors. We report a method ({LoFreq)} that models sequencing run-specific error rates to accurately call variants occurring in {\textless}0.05\% of a population. Using simulated and real datasets (viral, bacterial and human), we show that {LoFreq} has near-perfect specificity, with significantly improved sensitivity compared with existing methods and can efficiently analyze deep Illumina sequencing datasets without resorting to approximations or heuristics. We also present experimental validation for {LoFreq} on two different platforms (Fluidigm and Sequenom) and its application to call rare somatic variants from exome sequencing datasets for gastric cancer. Source code and executables for {LoFreq} are freely available at http://sourceforge.net/projects/lofreq/.},
	number = {22},
	urldate = {2013-12-18},
	journal = {Nucleic Acids Research},
	author = {Wilm, Andreas and Aw, Pauline Poh Kim and Bertrand, Denis and Yeo, Grace Hui Ting and Ong, Swee Hoe and Wong, Chang Hua and Khor, Chiea Chuen and Petric, Rosemary and Hibberd, Martin Lloyd and Nagarajan, Niranjan},
	month = dec,
	year = {2012},
	note = {{PMID:} 23066108
{PMCID:} {PMC3526318}},
	pages = {11189--11201},
	file = {PubMed Central Full Text PDF:/home/julian/embl/paper/storage/2XEWPTVC/Wilm et al. - 2012 - LoFreq a sequence-quality aware, ultra-sensitive .pdf:application/pdf}
}

@article{wolfe_if_2002,
	title = {If we're so different, why do we keep overlapping? When 1 plus 1 doesn't make 2},
	volume = {166},
	issn = {0820-3946, 1488-2329},
	shorttitle = {If we're so different, why do we keep overlapping?},
	url = {http://www.cmaj.ca/content/166/1/65},
	language = {en},
	number = {1},
	urldate = {2014-01-10},
	journal = {Canadian Medical Association Journal},
	author = {Wolfe, Rory and Hanley, James},
	month = jan,
	year = {2002},
	note = {{PMID:} 11800251},
	pages = {65--66},
	file = {Full Text PDF:/home/julian/embl/paper/storage/JXU6G6MX/Wolfe and Hanley - 2002 - If we're so different, why do we keep overlapping.pdf:application/pdf;Snapshot:/home/julian/embl/paper/storage/4W3ZH49X/65.html:text/html}
}

@article{yates_evolution_2012,
	title = {Evolution of the cancer genome},
	volume = {13},
	url = {http://www.nature.com/nrg/journal/v13/n11/abs/nrg3317.html},
	doi = {10.1038/nrg3317},
	abstract = {The advent of massively parallel sequencing technologies has allowed the characterization of cancer genomes at an unprecedented resolution. Investigation of the mutational landscape of tumours is providing new insights into cancer genome evolution, laying bare the interplay of somatic mutation, adaptation of clones to their environment and natural selection. These studies have demonstrated the extent of the heterogeneity of cancer genomes, have allowed inferences to be made about the forces that act on nascent cancer clones as they evolve and have shown insight into the mutational processes that generate genetic variation. Here we review our emerging understanding of the dynamic evolution of the cancer genome and of the implications for basic cancer biology and the development of antitumour therapy.},
	number = {11},
	urldate = {2012-11-26},
	journal = {Nature Reviews Genetics},
	author = {Yates, Lucy R. and Campbell, Peter J.},
	month = nov,
	year = {2012},
	pages = {795},
	file = {Full Text PDF:/home/julian/embl/paper/storage/AI7N5QW4/Yates and Campbell - 2012 - Evolution of the cancer genome.pdf:application/pdf}
}